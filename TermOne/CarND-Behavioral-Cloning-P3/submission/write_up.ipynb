{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write up document for Behavioral Cloning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "[example_images]: ./images/example_images.jpg \"Example Images\"\n",
    "[center_image]: ./images/center_image.jpg \"Center Image\"\n",
    "[left_image]: ./images/left_image.jpg \"Left Image\"\n",
    "[right_image]: ./images/right_image.jpg \"Right Image\"\n",
    "[histogram_image]: ./images/steering_histogram.jpg \"Histogram Image\"\n",
    "[steering_group_image]: ./images/steering_group.jpg \"steering_group Image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal and Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Submission includes all required files and can be used to run the simulator in autonomous mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My project includes the following files:\n",
    "* model.py containing the script to create and train the model. This file is the main pipeline running Nvidia's model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* writeup_report.pdf summarizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Submission includes functional code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "python drive.py model.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Submission code is usable and readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. An appropriate model architecture has been employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used to train is Nvidia's self driving car architecture model. The network consists of 9 layers\n",
    "- 1 normalization layer\n",
    "- 5 Convolutional layers\n",
    "- 3 fully connected layers\n",
    "\n",
    "The model includes RELU layers to introduce non linearity and data is normalized using a Keras lambda layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer  | Description | Output Shape\n",
    "  ------------- | -------------  | -------------\n",
    " Resize Input image  | Sample data pass to model                             |  160 x 320 x 3\n",
    " Cropping Image  | Cropped Sample data pass to model                         |  65 x 320 x 3 \n",
    " Convolutional 2D  | First Convolution Layer, 2 x 2 stride , relu activation |  31 x 159 x 24\n",
    " Spatial Dropout  |        Reduce overfitting            |  31 x 159 x 24\n",
    " Convolutional 2D  | Second Convolution Layer, 2 x 2 stride, relu activation  |  14 x 78 x 36\n",
    " Spatial Dropout  |        Reduce overfitting            |  14 x 78 x 36\n",
    " Convolutional 2D  | Third Convolution Layer, 2 x 2 stride, relu activation  |  6 x 38 x 48\n",
    " Spatial Dropout  |       Reduce overfitting             |   6 x 38 x 48\n",
    "  Convolutional 2D  | Fourth Convolution Layer, relu activation  | 4 x 36 x 64\n",
    "  Spatial Dropout  |       Reduce overfitting             |  4 x 36 x 64\n",
    "  Convolutional 2D  | Fifth Convolution Layer, relu activation  | 2 x 34 x 64\n",
    "  Spatial Dropout  |     Reduce overfitting               |  2 x 34 x 64\n",
    "  Flatten  |                    |  1 x 4352\n",
    "  Dropout  |       Reduce overfitting             |  1 x 4352\n",
    "  Dense 1  |                    |  1 x 100\n",
    "  Dense 2  |                    |  1 x 50\n",
    "  Dense 3  |                    |  1 x 10\n",
    "  Dropout  |       Reduce overfitting             |  1 x 10\n",
    "  Dense 4  |                    |  1 x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Attempts to reduce overfitting in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The model contains dropout layers in order to reduce overfitting\n",
    "\n",
    "The model was trained and validated on different data sets to ensure that the model was not overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used an adam optimizer, so the learning rate was not tuned manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Appropriate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set given was used for training.\n",
    "\n",
    "```\n",
    "data_given/\n",
    "|\n",
    "|-- IMG/\n",
    "|\n",
    "|-- driving_log.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMG directory has the central, right and left frame of the driving data. Each row in the driving_log.csv sheet corresponds to the images with the steering angle, throttle, brake and speed of the car.\n",
    "\n",
    "\n",
    "Training data provided by Udacity was split to a ratio of 80:20. 80% for training and 20% for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture and Training Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Solution Design Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall strategy for deriving a model architecture was to implement the LeNet CNN and Nvidia's CNN.\n",
    "\n",
    "After a few rounds of test, Nvidia's CNN seems more suitable as it is able to navigate track 1 better.I thought this model might be appropriate because it is well documented and discussed by the tutorial video.\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. I found that my first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting. \n",
    "\n",
    "To combat the overfitting, I modified the model by adding layers of dropout. Dropout can be found in between convolutional 2d layers step.\n",
    "\n",
    "The final step was to run the simulator to see how well the car was driving around track one.\n",
    "\n",
    "At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Final Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to Model Architecture and Training Strategy section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. Creation of Training Set & Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dateset used was given by Udacity.\n",
    "\n",
    "\n",
    "- The images was cropped top 70 pixels and bottom 25 pixels as suggested by the tutorial in the video\n",
    "- Images were also augemented by flipping it 180 degrees\n",
    "- Augmented measurements were also added by negating the values.\n",
    "\n",
    "This increasees the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Dataset Captured by the simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset Images\n",
    "\n",
    "The training set images and corresponding angles in radian are shown in the image below\n",
    "\n",
    "![Example Images][example_images]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original, Left and Right Images\n",
    "\n",
    "Below are examples of data images capture by the simulator. \n",
    "\n",
    "\n",
    "\n",
    "The simulator has 3 camera sample frame for every movement it makes. Below are the examples\n",
    "\n",
    "### Center Image\n",
    "![Center Image][center_image]       \n",
    "\n",
    "### Left Original Image\n",
    "![Left Image][left_image]                    \n",
    "\n",
    "### Right Original Image\n",
    "![Right Image][right_image]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Steering Histogram Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the generated histogram , 0 rad in steering has a high frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steering Histogram\n",
    "![Histogram Image][histogram_image]       \n",
    "\n",
    "### Steering Data Group by Positive and Negative\n",
    "![Group Image][steering_group_image]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
